{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dataset.__iter__() is only supported when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b327ef7876b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Python_Code-ckxiZQVL/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       raise RuntimeError(\"dataset.__iter__() is only supported when eager \"\n\u001b[0m\u001b[1;32m    168\u001b[0m                          \"execution is enabled.\")\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dataset.__iter__() is only supported when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "for i in tf.data.Dataset.range(7).take(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tf.data.Dataset.range(7).take(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WindowDataset shapes: <tensorflow.python.data.ops.dataset_ops._NestedDatasetComponent object at 0x7f38f0604a90>, types: <tensorflow.python.data.ops.dataset_ops._NestedDatasetComponent object at 0x7f38f0604a90>>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.data.Dataset.range(7).window(3, 2, 1, True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tf.data.Dataset.range(7).window(3, 2, 1, True):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sliding window 搞定了!'''\n",
    "# window: NestedDatasetComponent is trouble some. Need to be flattened by flat_map\n",
    "# flat_map(lambda x: x.batch(2)): flatten the result and make it ready to output\n",
    "ds = tf.data.Dataset.range(7).shuffle(buffer_size=5).window(2, 1, 1, True).flat_map(lambda x: x.batch(2)).batch(5)\n",
    "# stride: 决定[0, 1]这种list内的距离\n",
    "# shift:  决定[0, ..] [1, ..]这种list间的距离.\n",
    "\n",
    "\n",
    "it = ds.make_one_shot_iterator()\n",
    "data = it.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [3, 2],\n",
       "       [2, 1],\n",
       "       [1, 4],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected DataType for argument 'output_types' not <tensorflow.python.data.ops.dataset_ops._NestedDatasetComponent object at 0x7f1304411748>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/Python_Code-ckxiZQVL/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_type\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Python_Code-ckxiZQVL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot convert value %r to a TensorFlow DType.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert value <tensorflow.python.data.ops.dataset_ops._NestedDatasetComponent object at 0x7f1304411748> to a TensorFlow DType.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5d60816c8dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/Python_Code-ckxiZQVL/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    419\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                                           self._output_classes)),\n\u001b[0;32m--> 421\u001b[0;31m                                   name=name)), self._output_types,\n\u001b[0m\u001b[1;32m    422\u001b[0m         self._output_shapes, self._output_classes)\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Python_Code-ckxiZQVL/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2059\u001b[0m           \u001b[0;34m\"Expected list for 'output_types' argument to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m           \"'iterator_get_next' Op, not %r.\" % output_types)\n\u001b[0;32m-> 2061\u001b[0;31m     \u001b[0moutput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Python_Code-ckxiZQVL/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2059\u001b[0m           \u001b[0;34m\"Expected list for 'output_types' argument to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m           \"'iterator_get_next' Op, not %r.\" % output_types)\n\u001b[0;32m-> 2061\u001b[0;31m     \u001b[0moutput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Python_Code-ckxiZQVL/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_type\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     raise TypeError(\"Expected DataType for argument '%s' not %s.\" %\n\u001b[0;32m--> 126\u001b[0;31m                     (arg_name, repr(v)))\n\u001b[0m\u001b[1;32m    127\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected DataType for argument 'output_types' not <tensorflow.python.data.ops.dataset_ops._NestedDatasetComponent object at 0x7f1304411748>."
     ]
    }
   ],
   "source": [
    "a = tf.data.Dataset.range(7).window(3, 2, 1, True)\n",
    "\n",
    "iterator = a.make_one_shot_iterator()  \n",
    "next = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reinitializableI iterator \n",
    "**重新初始化的迭代器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 循环交替Trian & Evaluate\n",
    "reinitializableI iterator 在这里并不适用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################  epoch 0\n",
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n",
      "train:  <class 'numpy.int64'> 5\n",
      "train:  <class 'numpy.int64'> 6\n",
      "train:  <class 'numpy.int64'> 7\n",
      "train:  <class 'numpy.int64'> 8\n",
      "train:  <class 'numpy.int64'> 9\n",
      "evaluation start:\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "#########################  epoch 1\n",
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n",
      "train:  <class 'numpy.int64'> 5\n",
      "train:  <class 'numpy.int64'> 6\n",
      "train:  <class 'numpy.int64'> 7\n",
      "train:  <class 'numpy.int64'> 8\n",
      "train:  <class 'numpy.int64'> 9\n",
      "evaluation start:\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(100)\n",
    "validation_dataset = tf.data.Dataset.range(50)\n",
    "\n",
    "# A reinitializable iterator is defined by its structure. We could use the\n",
    "# `output_types` and `output_shapes` properties of either `training_dataset`\n",
    "# or `validation_dataset` here, because they are compatible.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                  training_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   # Run 20 epochs in which the training dataset is traversed, followed by the\n",
    "   # validation dataset.\n",
    "\n",
    "    for i in range(2):\n",
    "        print(\"#########################  epoch\", i)\n",
    "        # Initialize an iterator over the training dataset.\n",
    "        # 这样init的话，下个epoch的时候，有init，从头开始数了...\n",
    "        # 又不能放在epoch循环外面，因为这样的话，这个init会被下面的valid_init覆盖掉。。\n",
    "        sess.run(training_init_op)\n",
    "        for _ in range(10):\n",
    "            nel = sess.run(next_element)\n",
    "            print(\"train: \", type(nel), nel)\n",
    "        \n",
    "        sess.run(validation_init_op)\n",
    "        print('evaluation start:')\n",
    "        # Initialize an iterator over the validation dataset.\n",
    "        for _ in range(5):\n",
    "            nel = sess.run(next_element)\n",
    "            print(\"valid: \", type(nel), nel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 所有Train结束后Eval\n",
    "reinitializableI iterator很适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################  epoch 0\n",
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n",
      "train:  <class 'numpy.int64'> 5\n",
      "train:  <class 'numpy.int64'> 6\n",
      "train:  <class 'numpy.int64'> 7\n",
      "train:  <class 'numpy.int64'> 8\n",
      "train:  <class 'numpy.int64'> 9\n",
      "#########################  epoch 1\n",
      "train:  <class 'numpy.int64'> 10\n",
      "train:  <class 'numpy.int64'> 11\n",
      "train:  <class 'numpy.int64'> 12\n",
      "train:  <class 'numpy.int64'> 13\n",
      "train:  <class 'numpy.int64'> 14\n",
      "train:  <class 'numpy.int64'> 15\n",
      "train:  <class 'numpy.int64'> 16\n",
      "train:  <class 'numpy.int64'> 17\n",
      "train:  <class 'numpy.int64'> 18\n",
      "train:  <class 'numpy.int64'> 19\n",
      "evaluation start:\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "valid:  <class 'numpy.int64'> 5\n",
      "valid:  <class 'numpy.int64'> 6\n",
      "valid:  <class 'numpy.int64'> 7\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(100)\n",
    "validation_dataset = tf.data.Dataset.range(50)\n",
    "\n",
    "# A reinitializable iterator is defined by its structure. We could use the\n",
    "# `output_types` and `output_shapes` properties of either `training_dataset`\n",
    "# or `validation_dataset` here, because they are compatible.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                  training_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # train两个epoch，结束后再eval.\n",
    "    \n",
    "    # Initialize an iterator over the training dataset.\n",
    "    sess.run(training_init_op)\n",
    "    for i in range(2):\n",
    "        print(\"#########################  epoch\", i)\n",
    "        for _ in range(10):\n",
    "            nel = sess.run(next_element)\n",
    "            print(\"train: \", type(nel), nel)\n",
    "        \n",
    "    sess.run(validation_init_op)\n",
    "    print('evaluation start:')\n",
    "    # Initialize an iterator over the validation dataset.\n",
    "    for _ in range(8):\n",
    "        nel = sess.run(next_element)\n",
    "        print(\"valid: \", type(nel), nel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feedable iterator\n",
    "**可馈送的迭代器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################  0\n",
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n",
      "train:  <class 'numpy.int64'> 5\n",
      "train:  <class 'numpy.int64'> 6\n",
      "train:  <class 'numpy.int64'> 7\n",
      "train:  <class 'numpy.int64'> 8\n",
      "train:  <class 'numpy.int64'> 9\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "########################  1\n",
      "train:  <class 'numpy.int64'> 10\n",
      "train:  <class 'numpy.int64'> 11\n",
      "train:  <class 'numpy.int64'> 12\n",
      "train:  <class 'numpy.int64'> 13\n",
      "train:  <class 'numpy.int64'> 14\n",
      "train:  <class 'numpy.int64'> 15\n",
      "train:  <class 'numpy.int64'> 16\n",
      "train:  <class 'numpy.int64'> 17\n",
      "train:  <class 'numpy.int64'> 18\n",
      "train:  <class 'numpy.int64'> 19\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "########################  2\n",
      "train:  <class 'numpy.int64'> 20\n",
      "train:  <class 'numpy.int64'> 21\n",
      "train:  <class 'numpy.int64'> 22\n",
      "train:  <class 'numpy.int64'> 23\n",
      "train:  <class 'numpy.int64'> 24\n",
      "train:  <class 'numpy.int64'> 25\n",
      "train:  <class 'numpy.int64'> 26\n",
      "train:  <class 'numpy.int64'> 27\n",
      "train:  <class 'numpy.int64'> 28\n",
      "train:  <class 'numpy.int64'> 29\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "########################  3\n",
      "train:  <class 'numpy.int64'> 30\n",
      "train:  <class 'numpy.int64'> 31\n",
      "train:  <class 'numpy.int64'> 32\n",
      "train:  <class 'numpy.int64'> 33\n",
      "train:  <class 'numpy.int64'> 34\n",
      "train:  <class 'numpy.int64'> 35\n",
      "train:  <class 'numpy.int64'> 36\n",
      "train:  <class 'numpy.int64'> 37\n",
      "train:  <class 'numpy.int64'> 38\n",
      "train:  <class 'numpy.int64'> 39\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "########################  4\n",
      "train:  <class 'numpy.int64'> 40\n",
      "train:  <class 'numpy.int64'> 41\n",
      "train:  <class 'numpy.int64'> 42\n",
      "train:  <class 'numpy.int64'> 43\n",
      "train:  <class 'numpy.int64'> 44\n",
      "train:  <class 'numpy.int64'> 45\n",
      "train:  <class 'numpy.int64'> 46\n",
      "train:  <class 'numpy.int64'> 47\n",
      "train:  <class 'numpy.int64'> 48\n",
      "train:  <class 'numpy.int64'> 49\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(10000000).repeat(2)\n",
    "validation_dataset = tf.data.Dataset.range(5000000).repeat(2)\n",
    "\n",
    "# A feedable iterator is defined by a handle placeholder and its structure. We\n",
    "# could use the `output_types` and `output_shapes` properties of either\n",
    "# `training_dataset` or `validation_dataset` here, because they have\n",
    "# identical structure.\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# You can use feedable iterators with a variety of different kinds of iterator\n",
    "training_iterator = training_dataset.make_one_shot_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "    # and used to feed the `handle` placeholder.\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    # Loop forever, alternating between training and validation.\n",
    "    for i in range(5):\n",
    "        print(\"######################## epoch\", i)\n",
    "        i += 1\n",
    "        # Run 10 steps using the training dataset. Note that the training dataset is\n",
    "        # 2 * the original set, i.e. we run 2 epochs (see .repeat() argument), and we resume from where\n",
    "        # we left off in the previous `while` loop iteration.\n",
    "        for _ in range(10):\n",
    "            nel = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "            print(\"train: \", type(nel), nel)\n",
    "\n",
    "        # Run one pass over the validation dataset.\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for _ in range(5):\n",
    "            nel = sess.run(next_element, feed_dict={handle: validation_handle})\n",
    "            print(\"valid: \", type(nel), nel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    # Define training and validation datasets with the same structure.\n",
    "    training_dataset = tf.data.Dataset.range(10000000).repeat(2)\n",
    "    validation_dataset = tf.data.Dataset.range(5000000).repeat(2)\n",
    "\n",
    "    # A feedable iterator is defined by a handle placeholder and its structure. We\n",
    "    # could use the `output_types` and `output_shapes` properties of either\n",
    "    # `training_dataset` or `validation_dataset` here, because they have\n",
    "    # identical structure.\n",
    "    handle = tf.placeholder(tf.string, shape=[])\n",
    "    iterator = tf.data.Iterator.from_string_handle(\n",
    "        handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    # You can use feedable iterators with a variety of different kinds of iterator\n",
    "    training_iterator = training_dataset.make_one_shot_iterator()\n",
    "    validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "    return next_element, handle, training_iterator, validation_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n"
     ]
    }
   ],
   "source": [
    "next_element, handle, training_iterator, validation_iterator=input_fn()\n",
    "\n",
    "sess=tf.Session()\n",
    "# The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "# and used to feed the `handle` placeholder.\n",
    "training_handle = sess.run(training_iterator.string_handle())\n",
    "validation_handle = sess.run(validation_iterator.string_handle())\n",
    "\n",
    "for _ in range(5):\n",
    "    nel = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "    print(\"train: \", type(nel), nel)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "    # and used to feed the `handle` placeholder.\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    # Loop forever, alternating between training and validation.\n",
    "    for i in range(5):\n",
    "        print(\"######################## epoch\", i)\n",
    "        i += 1\n",
    "        # Run 10 steps using the training dataset. Note that the training dataset is\n",
    "        # 2 * the original set, i.e. we run 2 epochs (see .repeat() argument), and we resume from where\n",
    "        # we left off in the previous `while` loop iteration.\n",
    "        for _ in range(10):\n",
    "            nel = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "            print(\"train: \", type(nel), nel)\n",
    "\n",
    "        # Run one pass over the validation dataset.\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for _ in range(5):\n",
    "            nel = sess.run(next_element, feed_dict={handle: validation_handle})\n",
    "            print(\"valid: \", type(nel), nel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1250px",
    "left": "0px",
    "right": "2228px",
    "top": "106px",
    "width": "332px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
