{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reinitializableI iterator \n",
    "**重新初始化的迭代器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 循环交替Trian & Evaluate\n",
    "reinitializableI iterator 在这里并不适用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################  epoch 0\n",
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n",
      "train:  <class 'numpy.int64'> 5\n",
      "train:  <class 'numpy.int64'> 6\n",
      "train:  <class 'numpy.int64'> 7\n",
      "train:  <class 'numpy.int64'> 8\n",
      "train:  <class 'numpy.int64'> 9\n",
      "evaluation start:\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "#########################  epoch 1\n",
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n",
      "train:  <class 'numpy.int64'> 5\n",
      "train:  <class 'numpy.int64'> 6\n",
      "train:  <class 'numpy.int64'> 7\n",
      "train:  <class 'numpy.int64'> 8\n",
      "train:  <class 'numpy.int64'> 9\n",
      "evaluation start:\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(100)\n",
    "validation_dataset = tf.data.Dataset.range(50)\n",
    "\n",
    "# A reinitializable iterator is defined by its structure. We could use the\n",
    "# `output_types` and `output_shapes` properties of either `training_dataset`\n",
    "# or `validation_dataset` here, because they are compatible.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                  training_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   # Run 20 epochs in which the training dataset is traversed, followed by the\n",
    "   # validation dataset.\n",
    "\n",
    "    for i in range(2):\n",
    "        print(\"#########################  epoch\", i)\n",
    "        # Initialize an iterator over the training dataset.\n",
    "        # 这样init的话，下个epoch的时候，有init，从头开始数了...\n",
    "        # 又不能放在epoch循环外面，因为这样的话，这个init会被下面的valid_init覆盖掉。。\n",
    "        sess.run(training_init_op)\n",
    "        for _ in range(10):\n",
    "            nel = sess.run(next_element)\n",
    "            print(\"train: \", type(nel), nel)\n",
    "        \n",
    "        sess.run(validation_init_op)\n",
    "        print('evaluation start:')\n",
    "        # Initialize an iterator over the validation dataset.\n",
    "        for _ in range(5):\n",
    "            nel = sess.run(next_element)\n",
    "            print(\"valid: \", type(nel), nel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 所有Train结束后Eval\n",
    "reinitializableI iterator很适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################  epoch 0\n",
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n",
      "train:  <class 'numpy.int64'> 5\n",
      "train:  <class 'numpy.int64'> 6\n",
      "train:  <class 'numpy.int64'> 7\n",
      "train:  <class 'numpy.int64'> 8\n",
      "train:  <class 'numpy.int64'> 9\n",
      "#########################  epoch 1\n",
      "train:  <class 'numpy.int64'> 10\n",
      "train:  <class 'numpy.int64'> 11\n",
      "train:  <class 'numpy.int64'> 12\n",
      "train:  <class 'numpy.int64'> 13\n",
      "train:  <class 'numpy.int64'> 14\n",
      "train:  <class 'numpy.int64'> 15\n",
      "train:  <class 'numpy.int64'> 16\n",
      "train:  <class 'numpy.int64'> 17\n",
      "train:  <class 'numpy.int64'> 18\n",
      "train:  <class 'numpy.int64'> 19\n",
      "evaluation start:\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "valid:  <class 'numpy.int64'> 5\n",
      "valid:  <class 'numpy.int64'> 6\n",
      "valid:  <class 'numpy.int64'> 7\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(100)\n",
    "validation_dataset = tf.data.Dataset.range(50)\n",
    "\n",
    "# A reinitializable iterator is defined by its structure. We could use the\n",
    "# `output_types` and `output_shapes` properties of either `training_dataset`\n",
    "# or `validation_dataset` here, because they are compatible.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                  training_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # train两个epoch，结束后再eval.\n",
    "    \n",
    "    # Initialize an iterator over the training dataset.\n",
    "    sess.run(training_init_op)\n",
    "    for i in range(2):\n",
    "        print(\"#########################  epoch\", i)\n",
    "        for _ in range(10):\n",
    "            nel = sess.run(next_element)\n",
    "            print(\"train: \", type(nel), nel)\n",
    "        \n",
    "    sess.run(validation_init_op)\n",
    "    print('evaluation start:')\n",
    "    # Initialize an iterator over the validation dataset.\n",
    "    for _ in range(8):\n",
    "        nel = sess.run(next_element)\n",
    "        print(\"valid: \", type(nel), nel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feedable iterator\n",
    "**可馈送的迭代器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################  0\n",
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n",
      "train:  <class 'numpy.int64'> 5\n",
      "train:  <class 'numpy.int64'> 6\n",
      "train:  <class 'numpy.int64'> 7\n",
      "train:  <class 'numpy.int64'> 8\n",
      "train:  <class 'numpy.int64'> 9\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "########################  1\n",
      "train:  <class 'numpy.int64'> 10\n",
      "train:  <class 'numpy.int64'> 11\n",
      "train:  <class 'numpy.int64'> 12\n",
      "train:  <class 'numpy.int64'> 13\n",
      "train:  <class 'numpy.int64'> 14\n",
      "train:  <class 'numpy.int64'> 15\n",
      "train:  <class 'numpy.int64'> 16\n",
      "train:  <class 'numpy.int64'> 17\n",
      "train:  <class 'numpy.int64'> 18\n",
      "train:  <class 'numpy.int64'> 19\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "########################  2\n",
      "train:  <class 'numpy.int64'> 20\n",
      "train:  <class 'numpy.int64'> 21\n",
      "train:  <class 'numpy.int64'> 22\n",
      "train:  <class 'numpy.int64'> 23\n",
      "train:  <class 'numpy.int64'> 24\n",
      "train:  <class 'numpy.int64'> 25\n",
      "train:  <class 'numpy.int64'> 26\n",
      "train:  <class 'numpy.int64'> 27\n",
      "train:  <class 'numpy.int64'> 28\n",
      "train:  <class 'numpy.int64'> 29\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "########################  3\n",
      "train:  <class 'numpy.int64'> 30\n",
      "train:  <class 'numpy.int64'> 31\n",
      "train:  <class 'numpy.int64'> 32\n",
      "train:  <class 'numpy.int64'> 33\n",
      "train:  <class 'numpy.int64'> 34\n",
      "train:  <class 'numpy.int64'> 35\n",
      "train:  <class 'numpy.int64'> 36\n",
      "train:  <class 'numpy.int64'> 37\n",
      "train:  <class 'numpy.int64'> 38\n",
      "train:  <class 'numpy.int64'> 39\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n",
      "########################  4\n",
      "train:  <class 'numpy.int64'> 40\n",
      "train:  <class 'numpy.int64'> 41\n",
      "train:  <class 'numpy.int64'> 42\n",
      "train:  <class 'numpy.int64'> 43\n",
      "train:  <class 'numpy.int64'> 44\n",
      "train:  <class 'numpy.int64'> 45\n",
      "train:  <class 'numpy.int64'> 46\n",
      "train:  <class 'numpy.int64'> 47\n",
      "train:  <class 'numpy.int64'> 48\n",
      "train:  <class 'numpy.int64'> 49\n",
      "valid:  <class 'numpy.int64'> 0\n",
      "valid:  <class 'numpy.int64'> 1\n",
      "valid:  <class 'numpy.int64'> 2\n",
      "valid:  <class 'numpy.int64'> 3\n",
      "valid:  <class 'numpy.int64'> 4\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(10000000).repeat(2)\n",
    "validation_dataset = tf.data.Dataset.range(5000000).repeat(2)\n",
    "\n",
    "# A feedable iterator is defined by a handle placeholder and its structure. We\n",
    "# could use the `output_types` and `output_shapes` properties of either\n",
    "# `training_dataset` or `validation_dataset` here, because they have\n",
    "# identical structure.\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# You can use feedable iterators with a variety of different kinds of iterator\n",
    "training_iterator = training_dataset.make_one_shot_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "    # and used to feed the `handle` placeholder.\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    # Loop forever, alternating between training and validation.\n",
    "    for i in range(5):\n",
    "        print(\"######################## epoch\", i)\n",
    "        i += 1\n",
    "        # Run 10 steps using the training dataset. Note that the training dataset is\n",
    "        # 2 * the original set, i.e. we run 2 epochs (see .repeat() argument), and we resume from where\n",
    "        # we left off in the previous `while` loop iteration.\n",
    "        for _ in range(10):\n",
    "            nel = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "            print(\"train: \", type(nel), nel)\n",
    "\n",
    "        # Run one pass over the validation dataset.\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for _ in range(5):\n",
    "            nel = sess.run(next_element, feed_dict={handle: validation_handle})\n",
    "            print(\"valid: \", type(nel), nel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    # Define training and validation datasets with the same structure.\n",
    "    training_dataset = tf.data.Dataset.range(10000000).repeat(2)\n",
    "    validation_dataset = tf.data.Dataset.range(5000000).repeat(2)\n",
    "\n",
    "    # A feedable iterator is defined by a handle placeholder and its structure. We\n",
    "    # could use the `output_types` and `output_shapes` properties of either\n",
    "    # `training_dataset` or `validation_dataset` here, because they have\n",
    "    # identical structure.\n",
    "    handle = tf.placeholder(tf.string, shape=[])\n",
    "    iterator = tf.data.Iterator.from_string_handle(\n",
    "        handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    # You can use feedable iterators with a variety of different kinds of iterator\n",
    "    training_iterator = training_dataset.make_one_shot_iterator()\n",
    "    validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "    return next_element, handle, training_iterator, validation_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  <class 'numpy.int64'> 0\n",
      "train:  <class 'numpy.int64'> 1\n",
      "train:  <class 'numpy.int64'> 2\n",
      "train:  <class 'numpy.int64'> 3\n",
      "train:  <class 'numpy.int64'> 4\n"
     ]
    }
   ],
   "source": [
    "next_element, handle, training_iterator, validation_iterator=input_fn()\n",
    "\n",
    "sess=tf.Session()\n",
    "# The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "# and used to feed the `handle` placeholder.\n",
    "training_handle = sess.run(training_iterator.string_handle())\n",
    "validation_handle = sess.run(validation_iterator.string_handle())\n",
    "\n",
    "for _ in range(5):\n",
    "    nel = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "    print(\"train: \", type(nel), nel)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "    # and used to feed the `handle` placeholder.\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    # Loop forever, alternating between training and validation.\n",
    "    for i in range(5):\n",
    "        print(\"######################## epoch\", i)\n",
    "        i += 1\n",
    "        # Run 10 steps using the training dataset. Note that the training dataset is\n",
    "        # 2 * the original set, i.e. we run 2 epochs (see .repeat() argument), and we resume from where\n",
    "        # we left off in the previous `while` loop iteration.\n",
    "        for _ in range(10):\n",
    "            nel = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "            print(\"train: \", type(nel), nel)\n",
    "\n",
    "        # Run one pass over the validation dataset.\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for _ in range(5):\n",
    "            nel = sess.run(next_element, feed_dict={handle: validation_handle})\n",
    "            print(\"valid: \", type(nel), nel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1250px",
    "left": "0px",
    "right": "2228px",
    "top": "106px",
    "width": "332px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
