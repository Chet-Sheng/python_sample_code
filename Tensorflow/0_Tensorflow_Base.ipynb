{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations with variable as graph input\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Variable op. (define as input when running session)\n",
    "# tf Graph input\n",
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some operations\n",
    "add = tf.add(a, b)\n",
    "mul = tf.multiply(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition with variables: 5\n",
      "Multiplication with variables: 6\n"
     ]
    }
   ],
   "source": [
    "# Launch the default graph.\n",
    "with tf.Session() as sess:\n",
    "    # Run every operation with variable input\n",
    "    print (\"Addition with variables: %i\" % sess.run(add, feed_dict={a: 2, b: 3}))\n",
    "    print (\"Multiplication with variables: %i\" % sess.run(mul, feed_dict={a: 2, b: 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Transpose, reshape, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = tf.random_normal([2, 3], mean=-1, stddev=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm:\n",
      " [[[-4.4324436  -1.7864919  -0.4441982  -5.885107  ]\n",
      "  [-2.6136513  -5.5816164   1.5592961  -7.3064475 ]\n",
      "  [-5.1040425   1.5140333  -4.312895    0.38670862]]\n",
      "\n",
      " [[ 4.5946374   3.2871914   3.8917308  -1.2915606 ]\n",
      "  [ 0.66414404  1.3910279   1.5351808   0.6709045 ]\n",
      "  [ 2.3049917  -5.645281    2.3798478  -4.5707197 ]]]\n",
      "\n",
      "transpose:\n",
      " [[[-4.4324436  -1.7864919  -0.4441982  -5.885107  ]\n",
      "  [-2.6136513  -5.5816164   1.5592961  -7.3064475 ]\n",
      "  [-5.1040425   1.5140333  -4.312895    0.38670862]]\n",
      "\n",
      " [[ 4.5946374   3.2871914   3.8917308  -1.2915606 ]\n",
      "  [ 0.66414404  1.3910279   1.5351808   0.6709045 ]\n",
      "  [ 2.3049917  -5.645281    2.3798478  -4.5707197 ]]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "norm = tf.random_normal([2, 3, 4], mean=-1, stddev=4, seed=2)\n",
    "B=tf.transpose(norm, [0,1,2])\n",
    "#如果这两个不一起run的话，取值会不一样\n",
    "a,b = sess.run((norm, B))\n",
    "print('norm:\\n',a)\n",
    "print('\\ntranspose:\\n',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_norm:\n",
      " [[[-4.4324436  -1.7864919  -0.4441982  -5.885107  ]\n",
      "  [-2.6136513  -5.5816164   1.5592961  -7.3064475 ]\n",
      "  [-5.1040425   1.5140333  -4.312895    0.38670862]]\n",
      "\n",
      " [[ 4.5946374   3.2871914   3.8917308  -1.2915606 ]\n",
      "  [ 0.66414404  1.3910279   1.5351808   0.6709045 ]\n",
      "  [ 2.3049917  -5.645281    2.3798478  -4.5707197 ]]]\n",
      "\n",
      "X_transpose:\n",
      " [[[-4.4324436  -2.6136513  -5.1040425 ]\n",
      "  [-1.7864919  -5.5816164   1.5140333 ]\n",
      "  [-0.4441982   1.5592961  -4.312895  ]\n",
      "  [-5.885107   -7.3064475   0.38670862]]\n",
      "\n",
      " [[ 4.5946374   0.66414404  2.3049917 ]\n",
      "  [ 3.2871914   1.3910279  -5.645281  ]\n",
      "  [ 3.8917308   1.5351808   2.3798478 ]\n",
      "  [-1.2915606   0.6709045  -4.5707197 ]]]\n",
      "\n",
      "shape of b:\n",
      " (2, 4, 3)\n",
      "\n",
      "X_split:\n",
      " [array([[[-4.4324436 , -2.6136513 , -5.1040425 ],\n",
      "        [-1.7864919 , -5.5816164 ,  1.5140333 ],\n",
      "        [-0.4441982 ,  1.5592961 , -4.312895  ],\n",
      "        [-5.885107  , -7.3064475 ,  0.38670862]]], dtype=float32), array([[[ 4.5946374 ,  0.66414404,  2.3049917 ],\n",
      "        [ 3.2871914 ,  1.3910279 , -5.645281  ],\n",
      "        [ 3.8917308 ,  1.5351808 ,  2.3798478 ],\n",
      "        [-1.2915606 ,  0.6709045 , -4.5707197 ]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "X = tf.random_normal([2, 3, 4], mean=-1, stddev=4, seed=2)\n",
    "XT = tf.transpose(X, perm=[0,2,1])\n",
    "X_split = tf.split(XT, 2, axis=0)\n",
    "\n",
    "#如果这两个不一起run的话，取值会不一样\n",
    "a,b,c = sess.run((X, XT, X_split))\n",
    "print('X_norm:\\n',a)\n",
    "print('\\nX_transpose:\\n',b)\n",
    "print('\\nshape of b:\\n', np.shape(b))\n",
    "print('\\nX_split:\\n', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-4.4324436 , -2.6136513 , -5.1040425 ],\n",
       "        [-1.7864919 , -5.5816164 ,  1.5140333 ],\n",
       "        [-0.4441982 ,  1.5592961 , -4.312895  ],\n",
       "        [-5.885107  , -7.3064475 ,  0.38670862]],\n",
       "\n",
       "       [[ 4.5946374 ,  0.66414404,  2.3049917 ],\n",
       "        [ 3.2871914 ,  1.3910279 , -5.645281  ],\n",
       "        [ 3.8917308 ,  1.5351808 ,  2.3798478 ],\n",
       "        [-1.2915606 ,  0.6709045 , -4.5707197 ]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-4.4324436 , -2.6136513 , -5.1040425 ],\n",
       "        [-1.7864919 , -5.5816164 ,  1.5140333 ],\n",
       "        [-0.4441982 ,  1.5592961 , -4.312895  ],\n",
       "        [-5.885107  , -7.3064475 ,  0.38670862]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.slice\n",
    "- input: Tensor\n",
    "- begin: starting location for each dimension of input\n",
    "- size: number of elements for each dimension of input, **using -1 includes all remaining elements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[[1 1]\n",
      "  [2 2]\n",
      "  [3 3]]\n",
      "\n",
      " [[4 4]\n",
      "  [5 5]\n",
      "  [6 6]]]\n",
      "\n",
      "B:\n",
      " [[[1 1]\n",
      "  [2 2]]\n",
      "\n",
      " [[4 4]\n",
      "  [5 5]]]\n"
     ]
    }
   ],
   "source": [
    "# sess=tf.InteractiveSession()\n",
    "A=tf.constant([[[1,1],[2,2],[3,3]],[[4,4],[5,5],[6,6]]])\n",
    "'''\n",
    "tf.slice:\n",
    "-----------\n",
    "input: Tensor\n",
    "begin: starting location for each dimension of input\n",
    "size: number of elements for each dimension of input, using -1 includes all remaining elements\n",
    "'''\n",
    "B=tf.slice(A, begin=[0,0,0], size=[2, 2, 2])\n",
    "print('A:\\n',sess.run(A))\n",
    "print('\\nB:\\n',sess.run(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
    "                 [[3, 3, 3], [4, 4, 4]],\n",
    "                 [[5, 5, 5], [6, 6, 6]]])\n",
    "tmp1=tf.slice(t, [1, 0, 0], [1, 1, 3])  # [[[3, 3, 3]]]\n",
    "tmp2=tf.slice(t, [1, 0, 0], [1, 2, 3])  # [[[3, 3, 3], [4, 4, 4]]]\n",
    "tmp3=tf.slice(t, [1, 0, 0], [2, 1, 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 3, 3]]], dtype=int32)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 3, 3],\n",
       "        [4, 4, 4]]], dtype=int32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 3, 3]],\n",
       "\n",
       "       [[5, 5, 5]]], dtype=int32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tmp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.gather & tf.gather_nd\n",
    "- https://www.tensorflow.org/api_docs/python/tf/gather_nd\n",
    "- https://www.tensorflow.org/api_docs/python/tf/gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# tf.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = [[1, 2, 3], [4, 5, 6]]\n",
    "t2 = [[7, 8, 9], [10, 11, 12]]\n",
    "t3=[t1, t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12]], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.concat(t3, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-4.4324436 , -1.7864919 , -0.4441982 , -5.885107  ],\n",
       "        [-2.6136513 , -5.5816164 ,  1.5592961 , -7.3064475 ],\n",
       "        [-5.1040425 ,  1.5140333 , -4.312895  ,  0.38670862]],\n",
       "\n",
       "       [[ 4.5946374 ,  3.2871914 ,  3.8917308 , -1.2915606 ],\n",
       "        [ 0.66414404,  1.3910279 ,  1.5351808 ,  0.6709045 ],\n",
       "        [ 2.3049917 , -5.645281  ,  2.3798478 , -4.5707197 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "norm = tf.random_normal([2, 3, 4], mean=-1, stddev=4, seed=2)\n",
    "sess.run(tf.concat(norm, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.8800287 , -2.551282  , -2.8095226 ,  2.8253038 ],\n",
       "        [-3.3386943 ,  4.448929  , -3.208882  ,  0.83451724],\n",
       "        [-7.983199  , -3.5477114 ,  1.3000367 , -0.14389127]],\n",
       "\n",
       "       [[-1.6816882 , -4.810048  , -4.3068886 , -1.4531379 ],\n",
       "        [ 3.9501557 , -5.481842  , -4.223766  , -6.3029575 ],\n",
       "        [-2.6366472 , -5.7130976 , -4.6283875 , -2.1138787 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.where\n",
    "相当于**conditional if-statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 101 5200  303]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import os\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# Constants (3-element arrays).\n",
    "a = tf.constant([100, 200, 300])\n",
    "b = tf.constant([1, 2, 3])\n",
    "\n",
    "# Use placeholder for predicate to where.\n",
    "# ... We pass in an array of 3 bools to fill the placeholder.\n",
    "j = tf.placeholder(tf.bool, shape=(3,)) # 下面的那个array_temp是个list,所以用(3,), 不过用[3]也是对的...\n",
    "# j = tf.placeholder(tf.bool)\n",
    "\n",
    "# Use where to apply 1 of 2 methods based on each predicate.\n",
    "# ... First argument is the predicate (contains bools).\n",
    "#     Second argument is run when true.\n",
    "#     Third argument is run when false.\n",
    "x = tf.where(j, a + 5000, a + b)\n",
    "\n",
    "# Run with 3 bools in placeholder.\n",
    "array_temp = [False, True, False]\n",
    "result = tf.Session().run(x, {j: array_temp}) # use with to manage session is better\n",
    "\n",
    "# For false, add 2 elements toe get her.\n",
    "# ... For true, add 5000 to first element.\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.nn.sigmoid_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "# define diagonal matrix as labels.\n",
    "y=tf.diag([1,1,1,1])\n",
    "y=tf.cast(y, tf.float32)\n",
    "y.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1020602 ,  1.135856  , -0.07225064,  0.35086146],\n",
       "       [ 1.3675061 , -1.761079  ,  1.0870513 , -0.15497802],\n",
       "       [-1.6026533 , -0.00202283,  1.354184  ,  0.67207783],\n",
       "       [ 0.5506696 ,  0.20571461, -0.78620875,  0.41342178]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define logits\n",
    "z=tf.random_normal([4,4], seed=22)\n",
    "z.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28096822, 0.8032713 , 0.39847443, 2.1555412 ],\n",
       "       [0.672662  , 0.11806957, 0.6541165 , 0.9175534 ],\n",
       "       [1.2964976 , 0.57337654, 0.5237489 , 0.5544817 ],\n",
       "       [2.4085007 , 0.50966126, 0.7252496 , 0.27319372]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_cross_entropy=tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=z)\n",
    "sigmoid_cross_entropy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.4424815, 1.5473588, 3.3699217, 4.698089 ], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=tf.reduce_sum(sigmoid_cross_entropy, axis=1)\n",
    "loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.60500604  0.09188548  0.00325186]\n",
      " [ 0.26136604 -0.11349762 -0.23580375]\n",
      " [ 1.0784042   0.65485626 -0.73389983]\n",
      " [ 0.8080843   1.1454443   0.9186316 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3.1609292 , -1.1041467 , -2.821066  ,  0.16600364], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in case of not familiar with reduce_sum( , axis=...)\n",
    "test=tf.random_normal([4,3])\n",
    "print(test.eval())\n",
    "tf.reduce_sum(test, axis=1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.nn.softmax_cross_entropy_with_logits_v2\n",
    "\n",
    "反向传播会同时对 logits 和 labels 起作用， 要禁止反向传播对 labels 起作用，将 labels 传递给 tf.stop_gradients 即可.\n",
    "\n",
    "解释：https://lufficc.com/blog/tensorflow-notes\n",
    "- 在监督学习中，labels 可以视为常量，不参与方向传播，只需要调整权重来拟合 labels。但有些情况（如对抗神经网络）labels 可能来自不同的地方.\n",
    "- https://stats.stackexchange.com/questions/327348/how-is-softmax-cross-entropy-with-logits-different-from-softmax-cross-entropy-wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "label是placeholder的时候就不用stop_gradient，因为label不是variable. \n",
    "下面主要是针对GAN的。就算是RNN，我们的label也是placeholder输入的.\n",
    "'''\n",
    "\n",
    "tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                    labels=tf.stop_gradient(labels),\n",
    "                    logits=logits\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**下面是正常例子:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4143689 1.6642545]\n",
      "[1.4143689 1.6642545]\n",
      "[1.1718578 1.1757141]\n"
     ]
    }
   ],
   "source": [
    "'''这里的label是标准定义的prob dist.'''\n",
    "# 这边不知为何list也能跑，不过tensorflow内部流动都是tensor，正式做肯定还会是要转成tensor的\n",
    "labels = [[0.2,0.3,0.5],\n",
    "          [0.1,0.6,0.3]]\n",
    "logits = [[2,0.5,1],\n",
    "          [0.1,1,3]]\n",
    "logits_scaled = tf.nn.softmax(logits)\n",
    "\n",
    "result1 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits) # True\n",
    "result2 = -tf.reduce_sum(labels*tf.log(logits_scaled),1)\n",
    "result3 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits_scaled) # wrong!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(result1))\n",
    "    print (sess.run(result2))\n",
    "    print (sess.run(result3))\n",
    "# >>>[ 1.41436887  1.66425455]\n",
    "# >>>[ 1.41436887  1.66425455]\n",
    "# >>>[ 1.17185783  1.17571414]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4643688 2.1742544]\n"
     ]
    }
   ],
   "source": [
    "'''这里的label是onehot encoded的; 算是伪sprase_softmax_cross_entropy'''\n",
    "labels = [[0, 0, 1],\n",
    "          [0, 1, 0]]\n",
    "logits = [[2,0.5,1],\n",
    "          [0.1,1,3]]\n",
    "\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits) # True\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.nn.sparse_softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4643688 2.1742544]\n"
     ]
    }
   ],
   "source": [
    "'''这里的label不能是onehot encoded的，会报错'''\n",
    "# labels = tf.constant([[0, 0, 1],[0, 1, 0]])\n",
    "# labels = tf.constant([2, 1])\n",
    "# logits = tf.constant([[2, 0.5, 1], [0.1, 1, 3]])\n",
    "\n",
    "labels = [2, 1]\n",
    "logits = [[2, 0.5, 1], [0.1, 1, 3]]\n",
    "\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "# result1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits) # True\n",
    "# result2 = -tf.reduce_sum(labels*tf.log(logits_scaled),1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(cost))\n",
    "#     print (sess.run(result2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-1a010b15904c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# result1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits) # True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# result2 = -tf.reduce_sum(labels*tf.log(logits_scaled),1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   2038\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[1;32m   2039\u001b[0m                        \u001b[0;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[1;32m   2041\u001b[0m     if (static_shapes_fully_defined and\n\u001b[1;32m   2042\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n",
      "\u001b[0;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2)."
     ]
    }
   ],
   "source": [
    "'''Onehot encoded，报错版'''\n",
    "labels = tf.constant([[0, 0, 1],[0, 1, 0]])\n",
    "logits = tf.constant([[2, 0.5, 1], [0.1, 1, 3]])\n",
    "\n",
    "\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "# result1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits) # True\n",
    "# result2 = -tf.reduce_sum(labels*tf.log(logits_scaled),1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(cost))\n",
    "#     print (sess.run(result2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.nn.fixed_unigram_candidate_sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "labels_matrix = tf.reshape(tf.constant([1, 2, 3, 4], dtype=tf.int64), [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled_candidates: [19  4 11  2 10]\n",
      "True_expected_count: [[0.25]\n",
      " [0.25]\n",
      " [0.25]\n",
      " [0.25]]\n",
      "Sampled_expected_count: [0.25 0.25 0.25 0.25 0.25]\n"
     ]
    }
   ],
   "source": [
    "sampled_ids, true_expected_count, sampled_expected_count = tf.nn.fixed_unigram_candidate_sampler(\n",
    "true_classes = labels_matrix,\n",
    "num_true = 1,\n",
    "num_sampled = 5,\n",
    "unique = True,\n",
    "range_max = 20,\n",
    "distortion = 0.0,\n",
    "unigrams = list(range(20))\n",
    ")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sampled_candidates, True_expected_count, Sampled_expected_count = sess.run([sampled_ids, \n",
    "                                                            true_expected_count, sampled_expected_count])\n",
    "    print('sampled_candidates:',sampled_candidates)\n",
    "    # True_expected_count: probability of each true samples got sampled\n",
    "    print('True_expected_count:', True_expected_count)\n",
    "    # Sampled_expected_count: probability of each sampled class occured\n",
    "    print('Sampled_expected_count:',Sampled_expected_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Evaluation\n",
    "## tf.nn.top.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(range(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k value: [19 18 17]\n",
      "top_k index: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "Input=tf.constant(list(reversed(range(20))))\n",
    "top_k, top_idx=tf.nn.top_k(Input, k=3, sorted=True, name='top_k')\n",
    "with tf.Session() as sess:\n",
    "    print('top_k value:',sess.run(top_k))\n",
    "    print('top_k index:',sess.run(top_idx))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
